["00:00", "hello freak bitches do you think in our", "00:04", "lifetimes and/or in our children's", "00:06", "lifetime it's feasible that we figure", "00:10", "out a way in some way to I'm not", "00:14", "endorsing like taking people's money and", "00:16", "giving it to other people but in some", "00:17", "sort of a way to eliminate poverty is", "00:20", "that even possible", "00:21", "is it ever going to be possible to", "00:22", "completely eliminate poverty worldwide", "00:24", "and within like a lifetime well I think", "00:29", "we talked about this the last time when", "00:31", "we spoke about AI but I mean this is the", "00:33", "implication of much of what we talked", "00:36", "about here if you if you imagine", "00:37", "building the perfect labor saving", "00:40", "technology right where you met imagine", "00:43", "just having a machine that can build any", "00:47", "machine that can do any human labor you", "00:50", "powered by sunlight more or less for the", "00:52", "cost of raw materials right so you're", "00:54", "talking about the ultimate wealth", "00:56", "generation device and now we're not just", "00:58", "talking about blue-collar labor we're", "01:00", "talking about the kind of labor you and", "01:03", "I do right so like the artistic labor", "01:05", "and scientific labor and you know good", "01:08", "just a machine that comes up with good", "01:10", "ideas right we're talking about general", "01:12", "artificial intelligence this if in the", "01:17", "right political and economic system this", "01:20", "would just cancel any need for people to", "01:22", "have to work to survive right it just", "01:25", "would be there'd be enough of everything", "01:27", "to go around and then the question would", "01:30", "be do we have the right political and", "01:33", "economic system or where we actually", "01:34", "could spread that wealth or would we", "01:37", "just would we just find ourselves in", "01:39", "some kind of horrendous arms race and", "01:41", "and a situation of wealth inequality", "01:46", "unlike any we've ever seen it's a we", "01:51", "don't we don't have the it's not in", "01:53", "place now and if someone just handed us", "01:55", "this device you know if and it were you", "02:00", "know all of my concerns about AI were", "02:02", "gone I mean there's no question about", "02:04", "this thing doing things we didn't want", "02:06", "it would do exactly what we want when we", "02:09", "want it and there's no there's just no", "02:10", "danger of it it's", "02:13", "Criss becoming misaligned with our own", "02:14", "it's just like a perfect Oracle and a", "02:16", "perfect designer of new technology if it", "02:21", "was handed to us now you know I would", "02:24", "expect just complete chaos right I would", "02:28", "splay if Facebook built this thing", "02:30", "tomorrow and announced it or rumor", "02:33", "spread that they had built it right what", "02:35", "are the implications for Russia and", "02:37", "China well insofar as they are as", "02:41", "adversarial as they are now it would be", "02:43", "rational for them to just new California", "02:45", "right because it because the the", "02:48", "happiness device is just a", "02:50", "winner-take-all scenario I mean you win", "02:53", "the world if you have this device you", "02:55", "can turn the lights off in China you", "02:56", "know the moment you have this device you", "02:58", "can just it's just the ultimate because", "03:01", "literally a we're talking about and you", "03:04", "know many people are made out whether", "03:06", "such a thing is possible but again we're", "03:08", "just talking about the implications of", "03:11", "intelligence that can make refinements", "03:14", "to itself in overtime course that is", "03:20", "there's no relationship to what we", "03:22", "experienced as Apes right so you're", "03:24", "talking about a system that can make", "03:26", "changes to his own source code and", "03:29", "become better and better at learning and", "03:32", "more and more knowledgeable has instant", "03:34", "a nifty give it access to the Internet", "03:36", "it has instantaneous access to all human", "03:39", "and machine knowledge and it does you", "03:43", "know thousands of years of work every", "03:46", "every day of our lives right thousands", "03:50", "of years of equivalent human level", "03:52", "intellectual work it's just day it's on", "03:56", "I mean our intuitions completely falter", "03:58", "to capture just how immensely powerful", "04:01", "such a thing would be and there's no", "04:02", "reason to think this isn't possible I", "04:05", "mean the only the most skeptical thing", "04:07", "you can honestly say about this is that", "04:09", "this isn't coming soon right it's like", "04:12", "this is not but to say that this is not", "04:14", "possible", "04:15", "makes no scientific sense at this point", "04:17", "there's no reason to think that a", "04:20", "sufficiently advanced digital computer", "04:23", "can't", "04:25", "Perdue can't instantiate general", "04:27", "intelligence of a sort that we have", "04:28", "there's no reason to think that I mean", "04:30", "the intelligence has to be at bottom", "04:32", "some form of information processing and", "04:35", "if we get the algorithm right with", "04:37", "enough hardware resources and the limit", "04:41", "is definitely not the hardware at this", "04:43", "point it's it's the algorithms there's", "04:48", "just no reason to think this can't take", "04:50", "off and and scale and that we would be", "04:52", "in the presence of something that is", "04:54", "that is like having an an alternate", "04:58", "human civilization in a box that is", "05:01", "making thousands of years of progress", "05:03", "every day right so just imagine that if", "05:06", "you had in a box you know the ten", "05:08", "smartest people who have ever lived and", "05:10", "you know every time every week they make", "05:14", "twenty thousand years of progress right", "05:15", "because that is the actual in the we're", "05:18", "talking about electronic circuits being", "05:21", "a million times faster than biological", "05:22", "circuits so even if it was just and I", "05:26", "believe I said this the last time we", "05:27", "talked about AI but this is you know", "05:29", "this is what brings it home for me even", "05:31", "if it's just a matter of faster right", "05:33", "it's not it's not anything especially", "05:35", "spooky it's just this can do human level", "05:38", "intellectual work but just a million", "05:40", "times faster and again this totally", "05:44", "under cells the prospects of super", "05:47", "intelligence I think you know human", "05:49", "level intellectual work is is it's going", "05:52", "to seem pretty paltry in the end but if", "05:55", "you just imagine just speeding it up if", "05:57", "you imagine if we were doing this", "05:58", "podcast imagine how smart I would seem", "06:01", "if between every sentence I actually had", "06:05", "a year to figure out what I was going to", "06:08", "say next right and so I say this one", "06:10", "sentence and you say you ask me a", "06:11", "question and then in my world I just", "06:13", "have a year I'm gonna go spend the next", "06:15", "year getting getting ready for it for", "06:17", "Joe and it's going to be perfect and", "06:20", "this is just compounding upon itself", "06:23", "like not only can I not not only I am i", "06:27", "working faster ultimately I can change", "06:30", "my my ability to work faster I mean like", "06:33", "we're talking about software that can", "06:34", "change itself you're talking about", "06:35", "something that becomes you know self", "06:37", "improving", "06:38", "so there's a compounding function there", "06:39", "but it's the point is is unimaginable in", "06:46", "terms of how how much change this could", "06:51", "affect and if you imagine the best case", "06:54", "scenario where this is under our control", "06:55", "right where there's no alignment problem", "06:58", "where it's just it doesn't this thing", "06:59", "doesn't do anything that surprises us", "07:00", "this thing will always take direction", "07:02", "from us it will never it will never", "07:05", "develop interests of its own right which", "07:08", "is again the fear but let's let's just", "07:09", "say this is totally obedient it's just", "07:11", "an Oracle and a genie route you know in", "07:15", "in one and you know we say you know cure", "07:18", "Alzheimer's and it cures Alzheimer's", "07:20", "you know you solve the protein folding", "07:22", "problem and and it just it's just often", "07:25", "running and to develop a perfect", "07:26", "nanotechnology and it does that this is", "07:29", "all again going back to David Deutsch", "07:31", "there's no reason to think this isn't", "07:33", "possible because anything that's", "07:36", "compatible with the laws of physics can", "07:39", "be done given the requisite knowledge", "07:41", "right so you just you get enough", "07:44", "intelligence as long as you're not", "07:46", "violating the laws of physics you can do", "07:48", "something in that space so but the", "07:52", "problem is this is a winner-take-all", "07:53", "scenario so Facebook does it tomorrow", "07:55", "and China and Russia find out about it", "07:59", "they can't afford to wait around to see", "08:01", "whether the US decides to do something", "08:04", "not entirely selfish with this right", "08:07", "because that there were they may be", "08:09", "their worst fears could be realized if", "08:11", "Donald Trump is president what's Donald", "08:13", "Trump going to do with a perfect AI when", "08:14", "he has already told the world that he", "08:16", "you know hates Islam right it's a it's a", "08:22", "we would have to have a political and", "08:25", "economic system that allowed us to", "08:27", "absorb this ultimate wealth save it will", "08:31", "wealth producing technology and and", "08:33", "again so this may all sound like pure", "08:36", "sci-fi craziness to people I don't think", "08:39", "there is any reason to believe that it", "08:41", "is but walkway back from that edge of", "08:44", "craziness and just look at dumb AI you", "08:47", "narrow AI just self-driving cars and", "08:50", "automation", "08:51", "and intelligent algorithms that can do", "08:56", "human level work that is already poised", "09:01", "to change our world massively and create", "09:04", "massive wealth inequality which we have", "09:06", "we have to figure out how to spread this", "09:08", "wealth you know what do you do when you", "09:09", "can automate 50% of human labor were you", "09:15", "paying attention to the artificial", "09:17", "intelligence go match yeah it's not me I", "09:22", "don't actually play go so I wasn't", "09:23", "paying that kind of attention to it but", "09:25", "I'm aware of what happened there you", "09:27", "know the rules of go not not so I know", "09:31", "actually I don't I don't play it I know", "09:33", "I don't I don't know I know I know", "09:34", "vaguely how you how you how it looks", "09:36", "when a game is played but I don't", "09:38", "supposed to be very complicated though", "09:39", "yeah more complicated and more", "09:41", "possibilities than just yeah and that's", "09:44", "why I took 20 years longer for a", "09:47", "computer to be the best player in the", "09:49", "world it's it is did you see how the", "09:54", "computer did it - well I didn't I I know", "09:58", "I mean this is the company that did it", "10:00", "is deep mind which is was acquired by", "10:03", "Google and they're at the cutting edge", "10:05", "of AI research and yeah well it's the", "10:10", "cartoons are unfortunately not so far", "10:13", "from what is possible but the yeah I", "10:19", "mean there's again this is not-- this is", "10:22", "not general intelligence like we're", "10:24", "talking it so these are not machines", "10:26", "that can even play tic-tac-toe right now", "10:28", "there's some there have been some moves", "10:30", "away from this like deep mind has", "10:32", "trained an algorithm to play all of the", "10:36", "Atari games like from 1980 or whatever", "10:39", "and it is very quickly became super", "10:43", "human on most of them I think I don't", "10:45", "think it's super human on all of them", "10:46", "yet but it could play you know space", "10:48", "invaders and all these and break out all", "10:50", "these games that are too highly unlike", "10:57", "one another and it's the same algorithm", "11:00", "becoming expert and superhuman in all of", "11:02", "them and that's that's a new paradigm", "11:04", "and it's", "11:05", "technique called deep learning for that", "11:07", "and that's and that's been you know very", "11:11", "exciting and I will be incredibly useful", "11:13", "you know this is I mean the other the", "11:15", "flip side of all this I know that", "11:16", "everything I tend to say on this sounds", "11:18", "scary but this is all like I mean the", "11:21", "then the next scariest thing is not to", "11:24", "do any of this stuff it's like we want", "11:26", "intelligence we want automation we want", "11:28", "to figure out how to solve problems that", "11:30", "we can't yet solve so like intelligence", "11:32", "is the best thing we've got so we want", "11:34", "more of it but we have to have a system", "11:36", "where I mean it's scary that we have a", "11:38", "system where if you gave the best", "11:40", "possible version of it to one research", "11:44", "lab or to one government it's not", "11:47", "obvious that that wouldn't destroy", "11:50", "humanity right that wouldn't lead to", "11:53", "massive dislocations where you'd have", "11:55", "you know some trillionaire who's", "11:56", "trumpeting his new device and and just", "11:59", "you know 50% unemployment in the u.s.", "12:01", "you know in a month right like it's not", "12:04", "obvious how we would absorb this level", "12:07", "of progress and we we definitely have to", "12:11", "to figure out how to do it and oh of", "12:14", "course we can't assume the best-case", "12:15", "scenario right that's the best-case", "12:17", "scenario I think there's a few people", "12:19", "that put it the way you put it that", "12:22", "terrify the shit out of people right and", "12:24", "everyone else seems to have this rosy", "12:27", "vision of increased longevity and", "12:29", "automated everything and everything", "12:32", "fixed and easy to get to work and", "12:34", "medical procedures would be easier", "12:37", "they're going to know how to do it but", "12:38", "everybody looks at it like we are always", "12:40", "going to be here but are we obsolete I", "12:43", "mean is this idea of a living thing", "12:45", "that's creative and wrapped up in", "12:47", "emotions and lust and desires and", "12:50", "jealousy and all the pettiness that we", "12:52", "see celebrated all the time we still see", "12:54", "it it's not getting any better right if", "12:57", "are we obsolete I mean what if this", "13:00", "thing comes along and says listen", "13:01", "there's a way to do you can abandon all", "13:03", "that stupid shit you can abandon all", "13:06", "that makes you all that stuff that makes", "13:07", "you fun to be around yeah", "13:09", "it also fucks with you can live three", "13:10", "times as long without that stuff oh I I", "13:13", "think it it would in the best case would", "13:17", "usher", "13:18", "in a the possibility of kind of", "13:25", "fundamentally creative life where on the", "13:29", "order of something like the matrix", "13:30", "whether it's in the matrix or it's just", "13:32", "in the world that has been made as", "13:37", "beautiful as possible based on what", "13:44", "would functionally be an unlimited", "13:45", "resource of intelligence magista", "13:48", "selected for there to be a an ability to", "13:54", "solve problems of a sort that we can't", "13:57", "currently imagine I mean it's just it", "13:59", "really is like a place on the map that", "14:01", "you can't you can't you can indicate", "14:03", "it's over there you know it's like the", "14:05", "blank spot on the map is why it's called", "14:07", "the singularity right it's like this is", "14:09", "it this is a was it was John von Neumann", "14:11", "the the inventor of game theory who a", "14:15", "mathematician who is what you along with", "14:20", "Alan Turing and a couple of other people", "14:22", "is really responsible for the computer", "14:24", "revolution he was the first person to", "14:26", "use this term singularity to describe", "14:29", "just this that there's a speeding up of", "14:35", "information processing technology and", "14:39", "Apryl a cultural reliance upon it beyond", "14:43", "which we can't actually foresee the", "14:45", "level of change that can come over our", "14:47", "society it's like you know an event", "14:49", "horizon past which we can't see and this", "14:54", "certainly becomes true when you talk", "14:55", "about these intelligent systems being", "14:58", "able to make changes to themselves and", "15:01", "again we're talking mostly software it's", "15:03", "not I'm not imagining I mean the most", "15:07", "important breakthroughs or most", "15:08", "certainly at the level of better", "15:10", "software I mean is we have you in terms", "15:13", "of the computing power that the physical", "15:16", "physical Hardware on earth it's not", "15:19", "that's not what's limiting our AI at the", "15:21", "moment something we need more more", "15:24", "hardware but we will get more hardware", "15:28", "to up to the limits of physics and it'll", "15:30", "get smaller and smaller", "15:31", "it has and you know if quantum computing", "15:35", "becomes possible or practical that will", "15:40", "actually David Deutsch is is the", "15:43", "physicist I mentioned is one of the", "15:45", "fathers of the concept of quantum", "15:47", "computing that will open up a whole", "15:51", "nother area a you know extreme of", "15:55", "computing power that is not at all", "15:58", "analogous to the kinds of machines we", "16:01", "have now but it's just when you imagine", "16:07", "a people don't people seem to always", "16:12", "want to I just had this conversation", "16:14", "with with Neil deGrasse Tyson on my", "16:16", "podcast he name-dropper yeah oh he was", "16:19", "just I'm scheming funky people I'm just", "16:21", "I'm just attributing these ideas to hell", "16:24", "he's not at all he doesn't take this", "16:26", "line at all he's not all he thinks is", "16:28", "all bullshit right he's not all worried", "16:30", "about AI what does he think he thinks", "16:32", "that you know we just we just use he's", "16:35", "drawing an analogy from how we you", "16:39", "currently use computers that they just", "16:41", "they just keep helping us do what we", "16:44", "want to do like we decide what we want", "16:45", "to do with computers and we just add", "16:47", "them to our process and that process", "16:49", "becomes automated and then we'll find", "16:52", "new jobs somewhere else like you didn't", "16:53", "you don't need a stenographer once you", "16:55", "have voice recognition technology and", "16:58", "that's not a problem a stenographer will", "17:00", "find something else to do and so the", "17:01", "economic dislocation isn't that bad and", "17:05", "computers will just get better than they", "17:08", "are and you eventually Siri will", "17:10", "actually work you know and you'll you'll", "17:12", "answer your questions well and you're", "17:14", "not it's not going to be a you know", "17:15", "laugh line what Siri said to you today", "17:17", "and then all of this will just proceed", "17:22", "to make life better right now none of", "17:27", "that is imagining what it will be like", "17:29", "to make because it would be a certain", "17:31", "point where you'll have systems that are", "17:34", "you know it's like the chat the best", "17:38", "chess player on earth is now always", "17:40", "going to be a computer right this is", "17:42", "never there's no it's not going to be a", "17:43", "human born tomorrow", "17:45", "that's going to be better than the best", "17:46", "computer I mean that's it like it's", "17:48", "already it's like it's so we have super", "17:50", "human chess players on earth now imagine", "17:53", "having computers that are super human at", "17:56", "every every task that is relevant every", "18:00", "intellectual task right so the best", "18:01", "physicist is a computer you know the", "18:04", "best medical diagnostician is a computer", "18:07", "the best prove our of math theorems is a", "18:11", "computer that's engineer as a computer", "18:12", "right then there's no there's no reason", "18:14", "why we're not headed there I mean it", "18:16", "would be the only reason I could see", "18:18", "we're not headed there is that something", "18:19", "massively dislocating happens that", "18:22", "prevents us from continuing to improve", "18:25", "our intelligent machines but if you just", "18:27", "it the moment you admit that", "18:29", "intelligence is just a matter of", "18:30", "information processing and you admit", "18:33", "that we will continue to improve our", "18:35", "machines unless something heinous", "18:37", "happens because it's this intelligence", "18:39", "and automation are the most valuable", "18:41", "things we have at a certain point", "18:45", "whether you think is in five years or", "18:46", "five hundred years we are going to find", "18:49", "ourselves in the presence of super", "18:52", "intelligent machines and then at that", "18:53", "point the the best source of innovation", "18:57", "for the next generation of software or", "19:00", "hardware or both will be the machines", "19:03", "themselves right so then so then you", "19:06", "just have then that's where you get what", "19:08", "what was what the mathematician I J good", "19:11", "described as the intelligence explosion", "19:13", "which is just the process can take off", "19:16", "on its own and this is where you know", "19:18", "the singularity people either either are", "19:22", "hopeful or worried but because there's", "19:27", "nothing there's no guarantee that this", "19:28", "process will be remain aligned with our", "19:32", "interests and every person who I meet", "19:35", "even you know very smart people like", "19:37", "Neil who says they're not worried about", "19:40", "this when you actually drill down on why", "19:43", "they're not worried you find that", "19:45", "they're actually not imagining machines", "19:49", "making changes to their own source code", "19:52", "and they're not abour or they're they", "19:57", "simply a", "19:59", "leave that this is so far away that we", "20:02", "don't have to worry about it now right", "20:04", "what and that's actually a non sequitur", "20:06", "I mean to say that this is far away is", "20:08", "not actually grappling with it's not an", "20:12", "argument this isn't going to happen and", "20:14", "it's based on what - and it's and it's", "20:18", "based on first of all there's no there's", "20:21", "no reason to believe Jamie want to find", "20:24", "out where there is there's no I mean we", "20:29", "don't know how long it will take us to", "20:30", "prepare for this right so like like if", "20:33", "you were if you knew this it was going", "20:35", "to take 50 years for this to happen", "20:38", "right is 50 years enough for us to", "20:41", "prepare politically and economically to", "20:43", "deal with the ramifications of this and", "20:46", "and to do it and to add to say nothing", "20:48", "of actually building the a ice safely in", "20:51", "a way that's aligned with our interest I", "20:53", "don't know I mean so 50 years is it's", "20:56", "like we've had the iPhone for what 10", "20:59", "years 9 years I mean it's like 50 years", "21:03", "not a lot of time right - deal - deal", "21:05", "with this and this is no reason to think", "21:10", "it's it's that far away if we keep", "21:13", "making progress means it's not it would", "21:16", "be amazing if it were 500 years away I", "21:18", "mean that that seems like it's it's it's", "21:20", "more likely me from what I in the sense", "21:24", "I get from the people who are doing this", "21:26", "work it's far more likely to be 50 years", "21:31", "than 500 years like you know I mean the", "21:38", "peat the people who think this is a long", "21:40", "long way off or I mean they're saying", "21:44", "you know fifty to a hundred years no one", "21:48", "says 500 years no no as far as I know no", "21:51", "one who's actually close to this work", "21:53", "and some people think it could be in", "21:56", "five years right I mean the people who", "21:58", "are you know like the deep mind people", "22:00", "who are very close to this are the sorts", "22:02", "of people who say because the people the", "22:04", "people who are closest work are", "22:06", "astonished by what's happened in the", "22:08", "last 10 years like we went from a place", "22:11", "of", "22:12", "you know very little progress too you", "22:15", "know", "22:15", "wow this is all of a sudden really", "22:19", "really interesting and powerful and and", "22:23", "again progress is compounding in a way", "22:25", "that's counterintuitive people", "22:27", "systematically overestimate how much", "22:30", "change can happen in a year and", "22:32", "underestimate how much change can happen", "22:34", "in ten years and you know as far as", "22:36", "estimating how much change can happen in", "22:37", "50 or 100 years I don't know that anyone", "22:40", "is good at that how could you be with", "22:44", "giant leaps come giant exponential leaps", "22:47", "off those leaps and it's it's almost", "22:49", "impossible for us to really predict what", "22:52", "we're going to be looking at fifty years", "22:53", "from now but I don't I don't know what", "22:57", "they're going to think about us that's", "22:58", "what's most bizarre about it is we", "23:01", "really might be obsolete if we look at", "23:03", "how ridiculous we are look at this", "23:05", "political campaign look at what we pay", "23:07", "attention to in the news look at the", "23:09", "things we really focus on we're a", "23:11", "strange ridiculous animal and why if we", "23:14", "look back on you know some strange", "23:17", "dinosaur that had a weird neck why", "23:19", "should that fucking thing make it you", "23:21", "know why should we make it we might be", "23:23", "here to make that thing and that thing", "23:25", "takes over from here with no emotions no", "23:28", "lusts no greed and just purely existing", "23:32", "electronically and for what reason well", "23:34", "that's a little scary there are there", "23:36", "are computer scientists who when you", "23:38", "talk about why they're not worried or", "23:41", "talk to them about why they're not", "23:42", "worried they just swallow this pill", "23:46", "without any qualms we're going to make", "23:49", "the thing that is far more powerful and", "23:52", "beautiful and important than we are and", "23:55", "it doesn't matter what happens to us I", "23:57", "mean that was our role our role was to", "23:59", "build these mechanical gods and and it's", "24:05", "fine if they squash us and I've", "24:09", "literally heard a people say heard", "24:11", "someone give a talk I mean that that's", "24:13", "what woke me up - OH - how interesting", "24:17", "this area is I went to this conference", "24:18", "in San Juan about a year ago and there", "24:23", "were", "24:24", "you know like the people from deep mind", "24:26", "were there and there were the people who", "24:28", "were very close to this work were there", "24:29", "and I mean to hear some of the reasons", "24:34", "why you shouldn't be worried from people", "24:36", "who were interested in in calming the", "24:39", "fears so they could get on with doing", "24:41", "their very important work it was amazing", "24:44", "because they were highly uncompelled", "24:49", "reasons not to be worried you know it", "24:51", "was just so so they had a they had a", "24:56", "desire to be compelled they're not", "24:58", "they're not well not at all i well know", "25:00", "that they're people people want to do", "25:02", "this work there's a deep assumption in", "25:05", "many of these people that we can figure", "25:08", "it out as we go along right it's like", "25:10", "you know it's just like we're gonna", "25:12", "we're just going to get we're going to", "25:14", "get closer we're foot we're far enough", "25:15", "away now even five-year even if it's", "25:17", "five years five year once we get closer", "25:20", "once we get something a little scary", "25:21", "then we'll pull the brakes and talk", "25:25", "about it but the problem is they are a", "25:28", "sent everyone is essentially in a race", "25:30", "condition by default and you have you", "25:31", "know Google is racing against Facebook", "25:33", "and the u.s. is racing against China and", "25:36", "every every group is racing against", "25:38", "every other group however you want to", "25:42", "conceive of groups this this is a to be", "25:44", "the first one to be the first one with", "25:50", "incredibly powerful narrow AI is to be", "25:54", "the next you know multi-billion dollar", "25:57", "company right so everyone's trying to", "25:59", "get there and if they suddenly get there", "26:02", "and sort of overshoot a little bit and", "26:04", "now they've got something like you know", "26:05", "general intelligence", "26:06", "you know something close what we're", "26:09", "relying on every and and they know", "26:11", "everyone else is too attempting to do", "26:12", "this right we don't have a system set up", "26:16", "where everyone can pull the brakes", "26:19", "together and say listen we got to stop", "26:21", "racing here we have to share everything", "26:23", "we have to share the wealth we have to", "26:25", "share the information we have to this", "26:28", "truly has to be open source in every", "26:30", "conceivable way and we have to defuse", "26:34", "this winner-take-all dynamic", "26:38", "you know I think we need something like", "26:40", "a Manhattan Project to figure out how to", "26:42", "do that you know not if not to figure", "26:44", "out how to build the AI but to figure", "26:46", "out how to build it in a way that does", "26:48", "not create an arms race that does not", "26:50", "create an incentive to build unsafe AI", "26:54", "which is almost certainly going to be", "26:56", "easier than building safe AI and just to", "26:59", "work out all these issues because it's", "27:00", "it's not because what I think we are", "27:02", "we're going to build this by default", "27:04", "which is going to keep building more and", "27:07", "more intelligent machines and this is", "27:09", "going to be done in but everyone who can", "27:13", "can do it", "27:14", "you know as with each generation if we", "27:17", "were even talking about generations it's", "27:18", "going to be it will have the tools made", "27:21", "by the prior generation that are more", "27:23", "powerful than you know anyone imagined", "27:25", "100 years ago and it just it's going to", "27:27", "keep going like that did anybody", "27:29", "actually make that quote about giving", "27:32", "birth to the mechanical gods no that was", "27:34", "just me don't know yeah but it was there", "27:37", "was a scientist that actually was", "27:38", "thinking and saying that but that was", "27:40", "that was the content of what he was", "27:42", "saying because we're going to build the", "27:44", "next species that is far more important", "27:48", "than we are and that's a good thing and", "27:51", "what and actually I can go there with", "27:53", "him I mean it actually is he the only", "27:55", "only caveat here is that unless they're", "28:00", "not conscious right like so if you the", "28:03", "true horror for me is that we can build", "28:05", "things more intelligent than we are more", "28:07", "powerful than we are and that can squash", "28:12", "us and they might not they might be", "28:14", "unconscious right there might be nothing", "28:16", "like the universe could go dark if they", "28:18", "squashes right or at least our corner of", "28:20", "the universe could go dark right and yet", "28:22", "these things will be immensely powerful", "28:24", "so if and this is just you know the", "28:28", "jury's out on this but if there's", "28:29", "nothing about intelligence scaling that", "28:32", "demands that consciousness come along", "28:34", "for the ride", "28:36", "then it's possible that I mean nobody", "28:38", "thinks our machines are you know very", "28:39", "few people would think our machines that", "28:42", "are intelligent are conscious right so", "28:44", "at what point does consciousness come", "28:46", "online maybe it's possible to build", "28:49", "super intelligence that's unconscious", "28:51", "you know super-powerful does everything", "28:53", "better than we do you know it'll", "28:55", "recognize your emotion better than then", "28:57", "another person can but then the lights", "29:00", "aren't on that's that's also I think", "29:03", "possible you know maybe but maybe it's", "29:05", "not possible but that's that's the worst", "29:07", "case scenario because it in the ethical", "29:10", "silver lining and speaking you know", "29:13", "outside of our self-interest now but", "29:15", "just from a bird's eye view the ethical", "29:20", "silver lining to building these", "29:22", "mechanical gods that are conscious is", "29:24", "that yes okay we in fact if we have", "29:26", "built something that is far wiser and", "29:30", "has far you know more beautiful", "29:31", "experiences and deeper experiences of", "29:33", "the universe and we could ever imagine", "29:34", "and there-there's something that it's", "29:37", "like to be that thing that's just you", "29:39", "know it is it has a kind of god-like", "29:42", "experience well that would be a very", "29:44", "good thing then we will have built we", "29:47", "will have built something that was you", "29:48", "know if you stand outside of our narrow", "29:50", "self-interest I can understand why the", "29:53", "he would say that he was just assuming", "29:55", "what was scary about that particular", "29:58", "talk because he was assuming that", "30:00", "consciousness comes along for the ride", "30:02", "here and I don't know that that is a", "30:05", "safe assumption well in the really", "30:07", "terrifying thing is who if this is", "30:11", "constantly improving itself and it's", "30:14", "under the beck and call of a person then", "30:16", "so it's either conscious well not so", "30:19", "conscious where it acts as itself right", "30:21", "it acts as an individual thinking unit", "30:23", "right or as a thing outside of its aware", "30:26", "right either it is or it isn't and if it", "30:29", "isn't aware and some person can", "30:31", "manipulate it like imagine if it's", "30:33", "getting ten thousand how many how many", "30:35", "thousands of years in a week did you say", "30:37", "well if it was just improvement it was", "30:40", "just a million times faster than we are", "30:42", "it's twenty thousand years twenty", "30:44", "thousand years in a week in a week in a", "30:45", "week so with every week this thing", "30:48", "constantly gets better at even doing", "30:50", "that right so it's reprogramming itself", "30:52", "so it's all exponential presumably it", "30:55", "just just imagine again you could keep", "30:58", "it in the most restricted case you could", "31:01", "just keep it at our level but justice", "31:04", "faster just a million times faster but", "31:06", "if it did all these things if we kept", "31:08", "going and kept every week was thousands", "31:10", "of years right we're gonna control it a", "31:12", "personal no I know perch that's even", "31:14", "more insane just imagine being in", "31:16", "dialogue with something that had that", "31:18", "that lived the twenty thousand years of", "31:21", "human progress in a week and you come", "31:24", "back you know on Monday and say listen", "31:27", "that thing I told you to do last Monday", "31:29", "I want to change that up and this thing", "31:31", "has made twenty thousand years of", "31:33", "progress and if it's in a condition", "31:36", "where it has access I mean so we're", "31:38", "matching this thing you know in a box", "31:40", "you know air-gapped from the internet", "31:43", "and it's got nothing it's got no way to", "31:45", "get out right even that is an unstable", "31:48", "situation but just imagine this emerging", "31:51", "in some way online right already being", "31:53", "out in the wild right so let's say it's", "31:55", "in a financial market right that's again", "32:00", "this is our what worries me most about", "32:02", "this and what is also interesting is", "32:04", "that our intuitions here I think the", "32:07", "primary intuition that people have is no", "32:10", "no that's just that's just not possible", "32:12", "or not at all likely but if you're going", "32:15", "to fun if you think it's impossible or", "32:17", "even unlikely you have to find something", "32:21", "wrong with the claim that intelligence", "32:24", "is just a matter of information", "32:26", "processing I don't know any scientific", "32:31", "reason to doubt that claim at the moment", "32:33", "and very good reasons to believe that", "32:38", "it's just undoubtable and the and you", "32:43", "have to doubt that we will continue to", "32:46", "make progress in the design of", "32:48", "intelligent machines and but once you", "32:52", "that then it's then that all this left", "32:54", "is just time right if if intelligence is", "32:57", "just information processing and we are", "33:00", "going to continue to build better and", "33:03", "better information processors at a", "33:06", "certain point we're going to build", "33:09", "something that is superhuman and so", "33:15", "whether it's in five years or 50 it's", "33:17", "- it's the biggest change in human", "33:20", "history I think we can imagine right so", "33:25", "and then people I what I thought fine I", "33:28", "keep finding myself in the presence of", "33:29", "people who seem at least to my eye to be", "33:32", "refusing to imagine it like they're", "33:34", "treating it like the y2k virus or", "33:37", "whatever where it's just the y2k bug", "33:38", "where it just may or may not be an issue", "33:41", "right like like it's a hypothetical like", "33:44", "maybe this is just we're going to get", "33:45", "there and it's going to be it's either", "33:47", "not going to happen or it's going to be", "33:49", "trivial but how you don't if you don't", "33:52", "have an argument for why this isn't", "33:53", "going to happen then you have to have", "33:57", "then then you're left with okay what's", "34:00", "it going to be like to have systems that", "34:04", "are better than we are at everything in", "34:08", "the intellectual space and you know what", "34:16", "will happen if that suddenly happens in", "34:18", "one country and not in another right", "34:19", "it's some it's a it has enormous", "34:24", "implications but it just sounds like", "34:25", "science fiction I don't know what's", "34:28", "scarier the idea that an artificial", "34:30", "intelligence can emerge it's conscious", "34:32", "it's aware of itself and then acts to", "34:35", "present protect itself or the idea that", "34:38", "a person a regular person like of today", "34:42", "the bead control of essentially a god", "34:44", "right because if this thing continues to", "34:47", "get smarter and smarter with every week", "34:48", "and more and more power and more and", "34:50", "more potential more and more", "34:52", "understanding thousands of years I mean", "34:54", "it's just yeah this one person a pregger", "34:58", "person controlling that is almost more", "35:01", "terrifying than creating a new life or", "35:03", "any group of people who don't have the", "35:05", "total welfare of humanity as their", "35:08", "central concern and just imagine me what", "35:10", "would what would China do with it now", "35:12", "right what would we do if we thought", "35:14", "China you know if I do or what or some", "35:17", "Chinese company was on the verge of this", "35:19", "thing what would it be rational for us", "35:22", "to do you know I mean with North Korea", "35:24", "had it it would be rational to nuke them", "35:26", "given what they say about what you know", "35:29", "their relationship with the rest", "35:31", "so it's some well that kind of power", "35:34", "just isn't rational that kind of powers", "35:37", "it's so life changing and so what", "35:40", "paradigm shifting right but if you to", "35:43", "wind this back to what someone like Neil", "35:45", "deGrasse Tyson would say is that the", "35:48", "only basis for fear is yeah don't give", "35:51", "your super intelligent AI to the next", "35:53", "Hitler right that's that's obviously bad", "35:56", "but if we don't if we're not idiots and", "36:00", "we just use it well we're fine and that", "36:03", "I think is an intuition that is just", "36:05", "that's just a failure to to unpack what", "36:08", "is entailed by again something like an", "36:14", "intelligence explosion a process that B", "36:16", "once once you're talking about something", "36:18", "that is able to change itself and you", "36:24", "have to get it so what would it be like", "36:25", "to guarantee let's say we decide okay", "36:28", "we're just not going to build anything", "36:29", "that can make changes to its own source", "36:30", "code you know any change to software at", "36:34", "a certain point is going to have to be", "36:35", "run through a human brain and we're", "36:38", "going to have veto power well is every", "36:40", "person working on a I'm going to abide", "36:43", "by that rule it's like we've agreed not", "36:45", "to clone humans right but you know we", "36:47", "going to stand by that agreement for the", "36:49", "rest of human history and is you know is", "36:52", "our agreement binding on China or", "36:54", "Singapore or you know any other country", "36:56", "that might think otherwise it's just we", "36:59", "have it's a free-for-all and at a", "37:00", "certain point we're going to be you know", "37:03", "close enough everyone's going to be", "37:05", "close enough to making the final", "37:06", "breakthrough that unless we we have some", "37:12", "agreement about how to proceed if", "37:14", "someone is going to get there first", "37:17", "that is a terrifying scenario of the", "37:21", "future you know you cemented this last", "37:23", "time you were here but you're not as", "37:26", "Extreme as this time you seem to be", "37:28", "accelerating on rhetoric yeah exactly", "37:30", "yes", "37:31", "I'm uh you're going deep yeah boy I hope", "37:35", "you're wrong I'm on team yeah I deal", "37:38", "deGrasse Tyson rice one yeah go kneel", "37:41", "and well and so in defense of the other", "37:45", "side too I should say that you know", "37:46", "David Deutsch also thinks I'm wrong but", "37:48", "he thinks I'm wrong because we will", "37:51", "integrate ourselves with these machines", "37:54", "I mean so that we've this will be", "37:55", "extensions of ourselves and they can't", "37:57", "help but be aligned with us because we", "37:59", "will we will be connected to them that", "38:01", "seems to be the only way we can all get", "38:02", "along we have to merge become one yeah", "38:04", "but I just think there's no there's no", "38:07", "deep reason why like even if we decided", "38:09", "to do that right like in the US or in", "38:12", "half the world one is I think there are", "38:15", "reasons to worry that even that could go", "38:17", "haywire but there's no guarantee that", "38:20", "someone else couldn't just build AI in a", "38:22", "box I'm if we can build AI such that we", "38:25", "can merge our brains with it", "38:28", "someone can also just build AI in a box", "38:30", "right and and that's and then then you", "38:35", "inherit all the other problems that", "38:36", "people are saying we don't have to worry", "38:37", "about if it was a good Coen Brothers", "38:39", "movie it would be invented in the middle", "38:41", "of the presidency of Donald Trump and so", "38:43", "that that's when a I would go live and", "38:46", "then a I would have to challenge Donald", "38:48", "Trump and I would have like an insult", "38:49", "contest today yeah with that that's when", "38:53", "this thing becomes so comically", "38:56", "terrifying where it's just just imagine", "38:59", "Donald Trump being in a position to make", "39:03", "the final decisions on topics like this", "39:06", "for the country that is acting is going", "39:11", "to do this almost certainly in the near", "39:12", "term it's like should we have a", "39:14", "Manhattan Project on this point mr.", "39:17", "president you know the idea that", "39:22", "anything of value could be happening", "39:24", "between his ears on this topic or 100", "39:27", "others like it I think is now really", "39:30", "inconceivable and so what what price", "39:35", "could we might we pay for that kind of", "39:37", "inattention and and you know", "39:40", "self-satisfied in attention to", "39:42", "these kinds of issues well this this", "39:45", "issue if if this is real and if this", "39:48", "could go live in 50 years this is the", "39:50", "issue Union unless we fuck ourselves up", "39:53", "beyond repair before then and shut the", "39:55", "power off if it keeps going yeah no I", "39:58", "think it is I think it is the issue but", "40:00", "unfortunately it's the it's the issue", "40:02", "that doesn't it sounds like a goof", "40:04", "yeah it does just sound does you sound", "40:06", "like a crackpot even worrying about this", "40:07", "issue sounds completely ridiculous but", "40:09", "that might be what's how it's sneaking", "40:11", "in yeah yeah may just just imagine that", "40:15", "the tiny increment that would make", "40:17", "suddenly make it compelling I mean just", "40:20", "imagine I mean chess doesn't do it", "40:23", "because chess is so far from any central", "40:25", "human concern but just imagine if your", "40:27", "if your phone recognized your emotional", "40:31", "state better than any and your best", "40:33", "friend or your wife or anyone in your", "40:35", "life and it did it reliably right cause", "40:38", "your body like that movie with watching", "40:41", "fo her yeah you falls in love with his", "40:43", "phone right I mean that's just not you", "40:46", "know that is not far all that far off", "40:49", "it's not it's a very discrete ability I", "40:51", "mean you could do that you could do that", "40:52", "without any any other ability in the", "40:55", "phone really it's like it doesn't it", "40:57", "doesn't have to to stand on the", "41:00", "shoulders of any other kind of", "41:02", "intelligence it could just you know it", "41:04", "just you have I mean this could be you", "41:07", "could do this with just brute force in", "41:08", "the same way that you have a great chess", "41:10", "player that doesn't necessarily", "41:11", "understand that it's playing chess you", "41:13", "could have you know it's a facial", "41:16", "recognition of emotion and the and the", "41:19", "tone of voice recognition of emotion and", "41:24", "the idea that it's going to it's going", "41:26", "to be a very long time for computers to", "41:28", "get better than people with that I think", "41:29", "is is very far-fetched I was thinking", "41:32", "yeah I think you're right I was just", "41:34", "thinking how strange to be if you had", "41:36", "like headphones on and your phone was in", "41:38", "your pocket and you have rational", "41:39", "conversations with your phone like your", "41:41", "phone knew you better than you know you", "41:42", "like I mean I don't know what to do I", "41:44", "mean I don't think I was out of line", "41:46", "she held at me I mean what should I say", "41:47", "and I would listen to every one of your", "41:50", "friends exactly trained up on that just", "41:52", "talk to you about and go listen man this", "41:53", "is what you got to do yes", "41:54", "way too vertical you're sounding angry", "41:56", "you got defensive you got defensive why", "41:59", "were you so don't apologize relax let's", "42:02", "all move on a geek accelerated or okay", "42:04", "you're right man right Matt and like", "42:06", "you're talking this little artificial of", "42:08", "artificial intelligence that we suggest", "42:10", "we go all right let's give it a shot and", "42:12", "like self-help guys in your phone like a", "42:14", "personal trainer in your phone how to", "42:16", "talk to girls", "42:17", "yeah slow down dude slow down you're", "42:21", "talking too fast gotta act cool yeah I", "42:24", "would I mean literally like giving you", "42:26", "information that would be like step wand", "42:27", "I'd be like the Sony Walkman and when", "42:29", "you had a Walkman like a cassette player", "42:31", "that was like looks like a VCR yeah", "42:34", "we're on our way to what we have today", "42:37", "where you have fucking 30 thousand songs", "42:39", "in your phone or something I think I", "42:41", "remember the first Walkman the first", "42:42", "thing it's when I back when I skied", "42:45", "there was something called it was called", "42:46", "astral Tunes or something it was like it", "42:48", "was like a car radio that that you could", "42:50", "just put on in a pack on your chest", "42:53", "yeah if they kept coming out with those", "42:56", "sounds they would get smaller and", "42:57", "smaller so then that little little dude", "42:59", "would start telling you yo man dude", "43:00", "listen", "43:01", "they keep replacing me every year just", "43:03", "let him stick me in your brain we'll be", "43:05", "together all the time yeah yeah I've", "43:08", "been giving you good advice for years", "43:09", "bro I mean your brain and so you and", "43:13", "this little artificial intelligence of", "43:14", "you have a relationship over time", "43:16", "eventually it talks you into getting", "43:18", "your head drilled and they screw it in", "43:20", "there and your artificial intelligence", "43:22", "is always powered by your central", "43:24", "nervous system", "43:24", "have you seen most of these movies like", "43:27", "did you see her and no I didn't know and", "43:30", "as Diana did you see ex machina", "43:32", "that was one my that was good top 10", "43:35", "all-time favorite movies yeah I love", "43:36", "that movie actually I liked it I saw it", "43:38", "twice I was slow to realize how well", "43:43", "they they did it I mean it was just the", "43:46", "first time I saw it I thought I wasn't", "43:50", "as impressed and I watched it again and", "43:51", "they really I mean first of all the", "43:53", "performance of I forgot the actress's", "43:57", "name go to vikander Alicia vikander uma", "44:01", "the woman who plays the robot in ex", "44:03", "machina is just fantastic but scary good", "44:07", "yeah talk you in anything", "44:08", "we're getting a little full on time yeah", "44:11", "what are we like five hours and a half", "44:12", "hours in but I just got a note how this", "44:14", "is about to fill up wait a minute how", "44:15", "many hours four and a half hours no our", "44:17", "computers about the Philip yeah we did", "44:19", "we just did a four and a half hour", "44:20", "pocket yeah we're ready to keep going to", "44:22", "Jesus I'm Jamie a cock ball oh I don't", "44:26", "know you know what man once you opened", "44:27", "up that box up Pandora's boxes about AI", "44:30", "that I haven't read discussion I've", "44:32", "looked up is there any sort of concept", "44:34", "of like autism in AI like a spectrum of", "44:37", "AI like oh there are dumb AI and there's", "44:40", "gonna be smart AI oh yeah yeah no so the", "44:42", "scary thing so that yes like the super", "44:45", "autism there's no across the board", "44:50", "there's an AI think that super", "44:52", "intelligence and motivation and goals", "44:55", "are totally separable so you could have", "44:57", "a super intelligent machine that is", "45:00", "purposed toward a goal that just seems", "45:03", "completely absurd and harmful and non", "45:06", "common sensical and they said the", "45:07", "example that Nick Bostrom uses in his in", "45:10", "his book super intelligence which was a", "45:12", "great book and did more to inform my", "45:15", "thinking on this topic than any other", "45:16", "source he talks about a paperclip", "45:19", "Maximizer you could you could build a", "45:21", "super intelligent paperclip Maximizer", "45:23", "now not that anyone would do this but", "45:24", "the point is you could build a machine", "45:27", "that was that was smarter than we are in", "45:30", "every conceivable way but all it wants", "45:32", "to do is produce paperclips right now", "45:34", "that seems counterintuitive but there's", "45:35", "no there's no reason when you kind of", "45:38", "dig deeply into this there's no reason", "45:40", "why you couldn't boat build a superhuman", "45:43", "paperclip Maximizer just wants to turn", "45:46", "everything you know just literally the", "45:47", "atoms in your body would be better used", "45:49", "as paperclips and so this is just the", "45:53", "point he's making is that super", "45:55", "intelligence could be very", "45:56", "counterintuitive it's not necessarily", "45:59", "going to inherit everything we find as", "46:02", "you know commonsensical or emotionally", "46:05", "appropriate or wise or desirable it", "46:08", "could be totally foreign totally trivial", "46:12", "in some way and", "46:14", "focused on something that means nothing", "46:16", "to us but means everything to it because", "46:18", "of some quirk and how its motivation", "46:20", "system is structured and yet it can", "46:23", "build the perfect nanotechnology that", "46:26", "will allow it to build more paperclips", "46:28", "right so and Lisa at least I don't think", "46:32", "anyone can see why that's ruled out in", "46:34", "advance I mean there's no reason why we", "46:36", "would intentionally build that but the", "46:38", "fear is we might build something that", "46:42", "either is not perfectly aligned with our", "46:47", "goals and our common sense that are in", "46:50", "our aspirations and that it could form", "46:53", "some kind of separate instrumental goals", "46:57", "to get what it's once wants that are", "46:59", "totally incompatible with life as we", "47:02", "know it and that's you know I mean again", "47:05", "the the examples of this are always", "47:06", "cartoonish like you know how Elon Musk", "47:08", "said you know if you built a super", "47:10", "intelligent machine you told it to", "47:11", "reduce spam well then it could just kill", "47:13", "all people that's a great way to reduce", "47:15", "spam right but see the reason why that's", "47:18", "lat I mean it's laughable but you", "47:20", "there's you can't assume the common", "47:22", "sense won't be there unless we've built", "47:24", "it right like you have to have", "47:25", "anticipated all of this you can't if you", "47:27", "say take me to the airport as fast as", "47:29", "you can again this is bostr\u00f6m you know", "47:31", "and you have a super intelligent", "47:33", "automatic car you know a self-driving", "47:37", "car you'll just you'll get to the", "47:39", "airport covered in vomit because it'll", "47:40", "just it's just going to go as fast as it", "47:42", "can go so it's a it's our intuitions", "47:48", "about what it would mean to be super", "47:50", "intelligent necessarily are I mean", "47:54", "there's no we have to correct for them", "47:56", "because I think our intuitions are bad", "English (auto-generated)"]